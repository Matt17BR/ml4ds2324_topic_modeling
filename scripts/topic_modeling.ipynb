{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script will explore topic modelling on the title, abstract and then abstract and title together using 3 different approaches (basic, stemming, and lemmatization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Title Only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>López-Valenciano A, Ayala F, Puerta JM, et al</td>\n",
       "      <td>A preventive model for muscle injuries: a nove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Li C</td>\n",
       "      <td>Predict the neural network mathematical model ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lu G</td>\n",
       "      <td>Evaluation model of young basketball players ’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wu L</td>\n",
       "      <td>The participating team ’s technical analysis o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zhang Q</td>\n",
       "      <td>Prediction based on basketball competition vid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Author  \\\n",
       "0  López-Valenciano A, Ayala F, Puerta JM, et al   \n",
       "1                                           Li C   \n",
       "2                                           Lu G   \n",
       "3                                           Wu L   \n",
       "4                                        Zhang Q   \n",
       "\n",
       "                                               Title  \n",
       "0  A preventive model for muscle injuries: a nove...  \n",
       "1  Predict the neural network mathematical model ...  \n",
       "2  Evaluation model of young basketball players ’...  \n",
       "3  The participating team ’s technical analysis o...  \n",
       "4  Prediction based on basketball competition vid...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#Load the CSV file with title only\n",
    "references = pd.read_csv(os.path.join('..','results','refs_systematic.csv'))\n",
    "references.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Finding the Most Common Words in Title (Basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('neural', 17), ('based', 15), ('team', 13), ('basketball', 12), ('network', 11), ('football', 11), ('data', 10), ('model', 9), ('using', 9), ('artificial', 8), ('performance', 8), ('analysis', 7), ('prediction', 7), ('tactical', 7), ('networks', 7), ('training', 7), ('soccer', 7), ('mining', 7), ('technical', 6), ('match', 6), ('volleyball', 6), ('learning', 5), ('application', 5), ('machine', 5), ('injury', 5), ('games', 4), ('handball', 4), ('game', 4), ('elite', 4), ('professional', 4)]\n"
     ]
    }
   ],
   "source": [
    "#Using the nltk package for topic modeling\n",
    "import nltk\n",
    "\n",
    "#Filtering out common words that are \"meaningless\" using stop words\n",
    "nltk.download('stopwords', quiet = True)\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "#Function for cleaning and preprocessing the titles in a basic way\n",
    "def basic_preproc(text):\n",
    "    #Lowercasing, punctuation removal, word tokenization, and stop word filtering\n",
    "    cleaned_titles = []\n",
    "    for sentence in text:\n",
    "        if isinstance(sentence, str):\n",
    "            #Replace hyphens and slashes with spaces, then split the text into words\n",
    "            #Lowercasing, punctuation removal, word tokenization, and stop words\n",
    "\n",
    "            words = sentence.lower().translate(str.maketrans('-/', '  ')).split()\n",
    "            words = sentence.lower().translate(str.maketrans('', '', string.punctuation)).split()\n",
    "            #taking into account words with more than 3 characters\n",
    "            words = [word for word in words if word not in stop_words and len(word) > 3] \n",
    "            cleaned_titles.extend(words)\n",
    "\n",
    "    return cleaned_titles\n",
    "\n",
    "#Preprocessing titles and counting\n",
    "cleaned_titles = basic_preproc(references['Title'])\n",
    "word_counts = Counter(cleaned_titles)\n",
    "words_basic_T = word_counts.most_common(30)\n",
    "\n",
    "print(words_basic_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Finding the Most Common Words in Title (Stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('network', 18), ('neural', 17), ('base', 15), ('team', 15), ('basketbal', 12), ('footbal', 12), ('model', 11), ('predict', 11), ('data', 10), ('perform', 9), ('use', 9), ('game', 8), ('artifici', 8), ('injuri', 7), ('analysi', 7), ('tactic', 7), ('train', 7), ('soccer', 7), ('match', 7), ('mine', 7), ('learn', 6), ('’s', 6), ('technic', 6), ('volleybal', 6), ('machin', 6), ('player', 5), ('athlet', 5), ('applic', 5), ('outcom', 5), ('evalu', 4)]\n"
     ]
    }
   ],
   "source": [
    "#Import necessary libraties\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "#Function for cleaning and preprocessing text with stemming\n",
    "def stem_preproc(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    #Lowercasing, punctuation removal, word tokenization, stemming and stop word filtering\n",
    "    cleaned_titles = []\n",
    "    for sentence in text:\n",
    "        if isinstance(sentence, str):\n",
    "            words = sentence.lower().translate(str.maketrans('-/', '  ')).split()\n",
    "            words = sentence.lower().translate(str.maketrans('', '', string.punctuation)).split()\n",
    "            stemmed_words = [stemmer.stem(word) for word in words if word not in stop_words]\n",
    "            cleaned_titles.extend(stemmed_words)\n",
    "\n",
    "    return cleaned_titles\n",
    "\n",
    "#Preprocessing titles and counting\n",
    "cleaned_titles = stem_preproc(references['Title'])\n",
    "word_counts = Counter(cleaned_titles)\n",
    "words_stemming_T = word_counts.most_common(30)\n",
    "\n",
    "print(words_stemming_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Finding the Most Common Words in Title (Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('network', 18), ('neural', 17), ('base', 15), ('team', 15), ('basketball', 12), ('football', 11), ('model', 10), ('data', 10), ('game', 8), ('prediction', 8), ('artificial', 8), ('performance', 8), ('injury', 7), ('analysis', 7), ('tactical', 7), ('soccer', 7), ('match', 7), ('mining', 7), ('technical', 6), ('training', 6), ('volleyball', 6), ('machine', 6), ('player', 5), ('athlete', 5), ('application', 5), ('outcome', 5), ('learn', 4), ('handball', 4), ('elite', 4), ('professional', 4)]\n"
     ]
    }
   ],
   "source": [
    "#Import necessary libraties\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "\n",
    "#Ensure necessary NLTK resources are downloaded\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "#Function to map NLTK's part of speech tags to those used by WordNet\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "#Function for cleaning and preprocessing text with lemmatization\n",
    "def lemma_preproc(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    #Lowercasing, punctuation removal, word tokenization, lemmatizing and stop word filtering\n",
    "    cleaned_titles = []\n",
    "    for sentence in text:\n",
    "        if isinstance(sentence, str):\n",
    "            words = sentence.lower().translate(str.maketrans('-/', '  ')).split()\n",
    "            words = sentence.lower().translate(str.maketrans('', '', string.punctuation)).split()\n",
    "            pos_tags = pos_tag(words)\n",
    "            lem_words = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags if word not in stop_words]\n",
    "            cleaned_titles.extend(lem_words)\n",
    "\n",
    "    return [word for word in cleaned_titles if len(word) > 3]\n",
    "\n",
    "#Preprocessing titles and counting\n",
    "cleaned_titles = lemma_preproc(references['Title'])\n",
    "word_counts = Counter(cleaned_titles)\n",
    "words_lemm_T = word_counts.most_common(30)\n",
    "\n",
    "print(words_lemm_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Displaying All Three Methods Together and Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4b75e th {\n",
       "  background-color: #f4f4f4;\n",
       "  color: black;\n",
       "}\n",
       "#T_4b75e_row0_col0, #T_4b75e_row0_col1, #T_4b75e_row0_col2, #T_4b75e_row0_col3, #T_4b75e_row0_col4, #T_4b75e_row0_col5, #T_4b75e_row0_col6, #T_4b75e_row0_col7, #T_4b75e_row0_col8, #T_4b75e_row0_col9, #T_4b75e_row1_col0, #T_4b75e_row1_col1, #T_4b75e_row1_col2, #T_4b75e_row1_col3, #T_4b75e_row1_col4, #T_4b75e_row1_col5, #T_4b75e_row1_col6, #T_4b75e_row1_col7, #T_4b75e_row1_col8, #T_4b75e_row1_col9, #T_4b75e_row2_col0, #T_4b75e_row2_col1, #T_4b75e_row2_col2, #T_4b75e_row2_col3, #T_4b75e_row2_col4, #T_4b75e_row2_col5, #T_4b75e_row2_col6, #T_4b75e_row2_col7, #T_4b75e_row2_col8, #T_4b75e_row2_col9 {\n",
       "  background-color: white;\n",
       "  color: black;\n",
       "  border-color: black;\n",
       "  border-style: solid;\n",
       "  border-width: 1px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4b75e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4b75e_level0_col0\" class=\"col_heading level0 col0\" >1st Most Common</th>\n",
       "      <th id=\"T_4b75e_level0_col1\" class=\"col_heading level0 col1\" >2nd Most Common</th>\n",
       "      <th id=\"T_4b75e_level0_col2\" class=\"col_heading level0 col2\" >3rd Most Common</th>\n",
       "      <th id=\"T_4b75e_level0_col3\" class=\"col_heading level0 col3\" >4th Most Common</th>\n",
       "      <th id=\"T_4b75e_level0_col4\" class=\"col_heading level0 col4\" >5th Most Common</th>\n",
       "      <th id=\"T_4b75e_level0_col5\" class=\"col_heading level0 col5\" >6th Most Common</th>\n",
       "      <th id=\"T_4b75e_level0_col6\" class=\"col_heading level0 col6\" >7th Most Common</th>\n",
       "      <th id=\"T_4b75e_level0_col7\" class=\"col_heading level0 col7\" >8th Most Common</th>\n",
       "      <th id=\"T_4b75e_level0_col8\" class=\"col_heading level0 col8\" >9th Most Common</th>\n",
       "      <th id=\"T_4b75e_level0_col9\" class=\"col_heading level0 col9\" >10th Most Common</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Method</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4b75e_level0_row0\" class=\"row_heading level0 row0\" >Basic</th>\n",
       "      <td id=\"T_4b75e_row0_col0\" class=\"data row0 col0\" >neural</td>\n",
       "      <td id=\"T_4b75e_row0_col1\" class=\"data row0 col1\" >based</td>\n",
       "      <td id=\"T_4b75e_row0_col2\" class=\"data row0 col2\" >team</td>\n",
       "      <td id=\"T_4b75e_row0_col3\" class=\"data row0 col3\" >basketball</td>\n",
       "      <td id=\"T_4b75e_row0_col4\" class=\"data row0 col4\" >network</td>\n",
       "      <td id=\"T_4b75e_row0_col5\" class=\"data row0 col5\" >football</td>\n",
       "      <td id=\"T_4b75e_row0_col6\" class=\"data row0 col6\" >data</td>\n",
       "      <td id=\"T_4b75e_row0_col7\" class=\"data row0 col7\" >model</td>\n",
       "      <td id=\"T_4b75e_row0_col8\" class=\"data row0 col8\" >using</td>\n",
       "      <td id=\"T_4b75e_row0_col9\" class=\"data row0 col9\" >artificial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b75e_level0_row1\" class=\"row_heading level0 row1\" >Stemming</th>\n",
       "      <td id=\"T_4b75e_row1_col0\" class=\"data row1 col0\" >network</td>\n",
       "      <td id=\"T_4b75e_row1_col1\" class=\"data row1 col1\" >neural</td>\n",
       "      <td id=\"T_4b75e_row1_col2\" class=\"data row1 col2\" >base</td>\n",
       "      <td id=\"T_4b75e_row1_col3\" class=\"data row1 col3\" >team</td>\n",
       "      <td id=\"T_4b75e_row1_col4\" class=\"data row1 col4\" >basketbal</td>\n",
       "      <td id=\"T_4b75e_row1_col5\" class=\"data row1 col5\" >footbal</td>\n",
       "      <td id=\"T_4b75e_row1_col6\" class=\"data row1 col6\" >model</td>\n",
       "      <td id=\"T_4b75e_row1_col7\" class=\"data row1 col7\" >predict</td>\n",
       "      <td id=\"T_4b75e_row1_col8\" class=\"data row1 col8\" >data</td>\n",
       "      <td id=\"T_4b75e_row1_col9\" class=\"data row1 col9\" >perform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b75e_level0_row2\" class=\"row_heading level0 row2\" >Lemmatization</th>\n",
       "      <td id=\"T_4b75e_row2_col0\" class=\"data row2 col0\" >network</td>\n",
       "      <td id=\"T_4b75e_row2_col1\" class=\"data row2 col1\" >neural</td>\n",
       "      <td id=\"T_4b75e_row2_col2\" class=\"data row2 col2\" >base</td>\n",
       "      <td id=\"T_4b75e_row2_col3\" class=\"data row2 col3\" >team</td>\n",
       "      <td id=\"T_4b75e_row2_col4\" class=\"data row2 col4\" >basketball</td>\n",
       "      <td id=\"T_4b75e_row2_col5\" class=\"data row2 col5\" >football</td>\n",
       "      <td id=\"T_4b75e_row2_col6\" class=\"data row2 col6\" >model</td>\n",
       "      <td id=\"T_4b75e_row2_col7\" class=\"data row2 col7\" >data</td>\n",
       "      <td id=\"T_4b75e_row2_col8\" class=\"data row2 col8\" >game</td>\n",
       "      <td id=\"T_4b75e_row2_col9\" class=\"data row2 col9\" >prediction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x16a422b50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def results_df(basic_df, stem_df, lemma_df):\n",
    "\n",
    "    #Using pandas to display the 10 most common words in a table for ease of comparison\n",
    "    results_df = pd.DataFrame({\n",
    "        'Method': ['Basic', 'Stemming', 'Lemmatization'],\n",
    "        '1st Most Common': [basic_df[0][0], stem_df[0][0], lemma_df[0][0]],\n",
    "        '2nd Most Common': [basic_df[1][0], stem_df[1][0], lemma_df[1][0]],\n",
    "        '3rd Most Common': [basic_df[2][0], stem_df[2][0], lemma_df[2][0]],\n",
    "        '4th Most Common': [basic_df[3][0], stem_df[3][0], lemma_df[3][0]],\n",
    "        '5th Most Common': [basic_df[4][0], stem_df[4][0], lemma_df[4][0]],\n",
    "        '6th Most Common': [basic_df[5][0], stem_df[5][0], lemma_df[5][0]],\n",
    "        '7th Most Common': [basic_df[6][0], stem_df[6][0], lemma_df[6][0]],\n",
    "        '8th Most Common': [basic_df[7][0], stem_df[7][0], lemma_df[7][0]],\n",
    "        '9th Most Common': [basic_df[8][0], stem_df[8][0], lemma_df[8][0]],\n",
    "        '10th Most Common': [basic_df[9][0], stem_df[9][0], lemma_df[9][0]]\n",
    "    })\n",
    "    results_df.set_index('Method', inplace=True)\n",
    "\n",
    "    #Applying basic styling to the table \n",
    "    styled_df = results_df.style.set_properties(**{\n",
    "        'background-color': 'white',  #Background color\n",
    "        'color': 'black',             #Font color\n",
    "        'border-color': 'black',      #Border color\n",
    "        'border-style': 'solid',      #Border style\n",
    "        'border-width': '1px'         #Border width\n",
    "    }).set_table_styles([{\n",
    "        'selector': 'th',\n",
    "        'props': [('background-color', '#f4f4f4'), ('color', 'black')]  #Header styling\n",
    "    }])\n",
    "    return styled_df\n",
    "\n",
    "titles_results = results_df(words_basic_T, words_stemming_T, words_lemm_T)\n",
    "\n",
    "titles_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Conclusion***: Lemmatization considers the context and part of speech of a word, leading to more accurate results as it reduces words to their dictionary form, but requires more computational power. Stemming is robust for search and indexing purposes as the exact form of a word is less important and is faster. It's interesting to note that some words such as \"team\" and \"basketball\" have drastic differences across the methods, whereas words such as \"football\" have more consistent positioning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Abstract Only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>López-Valenciano A, Ayala F, Puerta JM, et al</td>\n",
       "      <td>A preventive model for muscle injuries: a nove...</td>\n",
       "      <td>The application of contemporary statistical ap...</td>\n",
       "      <td>Medicine and science in sports and exercise</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Li C</td>\n",
       "      <td>Predict the neural network mathematical model ...</td>\n",
       "      <td>Deep learning has achieved impressive predicti...</td>\n",
       "      <td>Physical review letters</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lu G</td>\n",
       "      <td>Evaluation model of young basketball players ’...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wu L</td>\n",
       "      <td>The participating team ’s technical analysis o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zhang Q</td>\n",
       "      <td>Prediction based on basketball competition vid...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Author  \\\n",
       "0  López-Valenciano A, Ayala F, Puerta JM, et al   \n",
       "1                                           Li C   \n",
       "2                                           Lu G   \n",
       "3                                           Wu L   \n",
       "4                                        Zhang Q   \n",
       "\n",
       "                                               Title  \\\n",
       "0  A preventive model for muscle injuries: a nove...   \n",
       "1  Predict the neural network mathematical model ...   \n",
       "2  Evaluation model of young basketball players ’...   \n",
       "3  The participating team ’s technical analysis o...   \n",
       "4  Prediction based on basketball competition vid...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  The application of contemporary statistical ap...   \n",
       "1  Deep learning has achieved impressive predicti...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                       Journal    Year  \n",
       "0  Medicine and science in sports and exercise  2018.0  \n",
       "1                      Physical review letters  2020.0  \n",
       "2                                          NaN     NaN  \n",
       "3                                          NaN     NaN  \n",
       "4                                          NaN     NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the CSV file with references\n",
    "ref_abs = pd.read_csv(os.path.join('..','results','refs_abstracts_sys.csv'))\n",
    "ref_abs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 2.1 Finding the Most Common Words in Abstract (Basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('data', 27), ('team', 27), ('performance', 26), ('classification', 19), ('ball', 18), ('match', 16), ('indicators', 15), ('football', 15), ('learning', 14), ('analysis', 12)]\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing abstracts and counting\n",
    "cleaned_abstracts = basic_preproc(ref_abs['Abstract'])\n",
    "word_counts = Counter(cleaned_abstracts)\n",
    "words_basic_A = word_counts.most_common(10)\n",
    "\n",
    "print(words_basic_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Method is limited, as words like \"sport\" and \"sports\" will be counted separately. We will further apply lemmatization and stemming to address this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Finding the Most Common Words in Abstract (Stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('team', 34), ('perform', 33), ('use', 32), ('classifi', 28), ('data', 27), ('indic', 22), ('model', 21), ('classif', 19), ('match', 19), ('ball', 18)]\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing abstracts and counting\n",
    "cleaned_abstracts = stem_preproc(ref_abs['Abstract'])\n",
    "word_counts = Counter(cleaned_abstracts)\n",
    "words_stemming_A = word_counts.most_common(10)\n",
    "\n",
    "print(words_stemming_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Most Common words in Abstract (Lematization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('team', 34), ('data', 27), ('performance', 26), ('model', 20), ('classification', 19), ('match', 19), ('ball', 18), ('indicator', 18), ('classify', 16), ('outcome', 16)]\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing the abstracts and counting\n",
    "cleaned_abstracts = lemma_preproc(ref_abs['Abstract'])\n",
    "word_counts = Counter(cleaned_abstracts)\n",
    "words_lemm_A = word_counts.most_common(10)\n",
    "\n",
    "print(words_lemm_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Displaying All Three Methods Together and Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_587c7 th {\n",
       "  background-color: #f4f4f4;\n",
       "  color: black;\n",
       "}\n",
       "#T_587c7_row0_col0, #T_587c7_row0_col1, #T_587c7_row0_col2, #T_587c7_row0_col3, #T_587c7_row0_col4, #T_587c7_row0_col5, #T_587c7_row0_col6, #T_587c7_row0_col7, #T_587c7_row0_col8, #T_587c7_row0_col9, #T_587c7_row1_col0, #T_587c7_row1_col1, #T_587c7_row1_col2, #T_587c7_row1_col3, #T_587c7_row1_col4, #T_587c7_row1_col5, #T_587c7_row1_col6, #T_587c7_row1_col7, #T_587c7_row1_col8, #T_587c7_row1_col9, #T_587c7_row2_col0, #T_587c7_row2_col1, #T_587c7_row2_col2, #T_587c7_row2_col3, #T_587c7_row2_col4, #T_587c7_row2_col5, #T_587c7_row2_col6, #T_587c7_row2_col7, #T_587c7_row2_col8, #T_587c7_row2_col9 {\n",
       "  background-color: white;\n",
       "  color: black;\n",
       "  border-color: black;\n",
       "  border-style: solid;\n",
       "  border-width: 1px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_587c7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_587c7_level0_col0\" class=\"col_heading level0 col0\" >1st Most Common</th>\n",
       "      <th id=\"T_587c7_level0_col1\" class=\"col_heading level0 col1\" >2nd Most Common</th>\n",
       "      <th id=\"T_587c7_level0_col2\" class=\"col_heading level0 col2\" >3rd Most Common</th>\n",
       "      <th id=\"T_587c7_level0_col3\" class=\"col_heading level0 col3\" >4th Most Common</th>\n",
       "      <th id=\"T_587c7_level0_col4\" class=\"col_heading level0 col4\" >5th Most Common</th>\n",
       "      <th id=\"T_587c7_level0_col5\" class=\"col_heading level0 col5\" >6th Most Common</th>\n",
       "      <th id=\"T_587c7_level0_col6\" class=\"col_heading level0 col6\" >7th Most Common</th>\n",
       "      <th id=\"T_587c7_level0_col7\" class=\"col_heading level0 col7\" >8th Most Common</th>\n",
       "      <th id=\"T_587c7_level0_col8\" class=\"col_heading level0 col8\" >9th Most Common</th>\n",
       "      <th id=\"T_587c7_level0_col9\" class=\"col_heading level0 col9\" >10th Most Common</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Method</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_587c7_level0_row0\" class=\"row_heading level0 row0\" >Basic</th>\n",
       "      <td id=\"T_587c7_row0_col0\" class=\"data row0 col0\" >data</td>\n",
       "      <td id=\"T_587c7_row0_col1\" class=\"data row0 col1\" >team</td>\n",
       "      <td id=\"T_587c7_row0_col2\" class=\"data row0 col2\" >performance</td>\n",
       "      <td id=\"T_587c7_row0_col3\" class=\"data row0 col3\" >classification</td>\n",
       "      <td id=\"T_587c7_row0_col4\" class=\"data row0 col4\" >ball</td>\n",
       "      <td id=\"T_587c7_row0_col5\" class=\"data row0 col5\" >match</td>\n",
       "      <td id=\"T_587c7_row0_col6\" class=\"data row0 col6\" >indicators</td>\n",
       "      <td id=\"T_587c7_row0_col7\" class=\"data row0 col7\" >football</td>\n",
       "      <td id=\"T_587c7_row0_col8\" class=\"data row0 col8\" >learning</td>\n",
       "      <td id=\"T_587c7_row0_col9\" class=\"data row0 col9\" >analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_587c7_level0_row1\" class=\"row_heading level0 row1\" >Stemming</th>\n",
       "      <td id=\"T_587c7_row1_col0\" class=\"data row1 col0\" >team</td>\n",
       "      <td id=\"T_587c7_row1_col1\" class=\"data row1 col1\" >perform</td>\n",
       "      <td id=\"T_587c7_row1_col2\" class=\"data row1 col2\" >use</td>\n",
       "      <td id=\"T_587c7_row1_col3\" class=\"data row1 col3\" >classifi</td>\n",
       "      <td id=\"T_587c7_row1_col4\" class=\"data row1 col4\" >data</td>\n",
       "      <td id=\"T_587c7_row1_col5\" class=\"data row1 col5\" >indic</td>\n",
       "      <td id=\"T_587c7_row1_col6\" class=\"data row1 col6\" >model</td>\n",
       "      <td id=\"T_587c7_row1_col7\" class=\"data row1 col7\" >classif</td>\n",
       "      <td id=\"T_587c7_row1_col8\" class=\"data row1 col8\" >match</td>\n",
       "      <td id=\"T_587c7_row1_col9\" class=\"data row1 col9\" >ball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_587c7_level0_row2\" class=\"row_heading level0 row2\" >Lemmatization</th>\n",
       "      <td id=\"T_587c7_row2_col0\" class=\"data row2 col0\" >team</td>\n",
       "      <td id=\"T_587c7_row2_col1\" class=\"data row2 col1\" >data</td>\n",
       "      <td id=\"T_587c7_row2_col2\" class=\"data row2 col2\" >performance</td>\n",
       "      <td id=\"T_587c7_row2_col3\" class=\"data row2 col3\" >model</td>\n",
       "      <td id=\"T_587c7_row2_col4\" class=\"data row2 col4\" >classification</td>\n",
       "      <td id=\"T_587c7_row2_col5\" class=\"data row2 col5\" >match</td>\n",
       "      <td id=\"T_587c7_row2_col6\" class=\"data row2 col6\" >ball</td>\n",
       "      <td id=\"T_587c7_row2_col7\" class=\"data row2 col7\" >indicator</td>\n",
       "      <td id=\"T_587c7_row2_col8\" class=\"data row2 col8\" >classify</td>\n",
       "      <td id=\"T_587c7_row2_col9\" class=\"data row2 col9\" >outcome</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x178e64f50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts_results = results_df(words_basic_A, words_stemming_A, words_lemm_A)\n",
    "\n",
    "abstracts_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Conclusion:***  Lemmatization considers the context and part of speech of a word, leading to more accurate results as it reduces words to their dictionary form, but requires more computational power. Stemming is robust for search and indexing purposes as the exact form of a word is less important and is faster. It's interesting to note that the word \"data\" is consistently the most common word across all 3 methods in the abstract and some words like \"risk\" have greatly varying positioning. Overall, compared to titles the differences are less extreme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accross both title and abstract, the most common words vary significantly. In the 3rd part we will discuss what are the most common words in both together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Title and Abstract Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Most Common Words in Title and Abstract (Basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('team', 40), ('data', 37), ('performance', 34), ('based', 26), ('football', 26), ('classification', 22), ('match', 22), ('neural', 21), ('using', 21), ('model', 20)]\n"
     ]
    }
   ],
   "source": [
    "#Columns are named 'Title' and 'Abstract' and combined_texts combines them\n",
    "#Replace NaN values with empty strings\n",
    "combined_texts = ref_abs['Title'].fillna('') + ' ' + ref_abs['Abstract'].fillna('')\n",
    "\n",
    "#Preprocessing titles and abstracts together and counting\n",
    "cleaned_texts = basic_preproc(combined_texts)\n",
    "word_counts = Counter(cleaned_texts)\n",
    "words_basic_TA = word_counts.most_common(10)\n",
    "\n",
    "print(words_basic_TA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Most Common Words in  Title and Abstract (Stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('team', 49), ('perform', 42), ('use', 41), ('data', 37), ('model', 32), ('predict', 28), ('classifi', 28), ('footbal', 28), ('base', 26), ('network', 26)]\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing the abstracts and counting\n",
    "cleaned_texts = stem_preproc(combined_texts)\n",
    "word_counts = Counter(cleaned_texts)\n",
    "words_stemming_TA = word_counts.most_common(10)\n",
    "\n",
    "print(words_stemming_TA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Most Common Words in  Title and Abstract (Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('team', 49), ('data', 37), ('performance', 34), ('model', 30), ('base', 26), ('network', 26), ('match', 26), ('football', 26), ('classification', 22), ('analysis', 22)]\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing the abstracts and counting\n",
    "cleaned_texts = lemma_preproc(combined_texts)\n",
    "word_counts = Counter(cleaned_texts)\n",
    "words_lemm_TA = word_counts.most_common(10)\n",
    "\n",
    "print(words_lemm_TA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Displaying all Three Methods Together and Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_540cb th {\n",
       "  background-color: #f4f4f4;\n",
       "  color: black;\n",
       "}\n",
       "#T_540cb_row0_col0, #T_540cb_row0_col1, #T_540cb_row0_col2, #T_540cb_row0_col3, #T_540cb_row0_col4, #T_540cb_row0_col5, #T_540cb_row0_col6, #T_540cb_row0_col7, #T_540cb_row0_col8, #T_540cb_row0_col9, #T_540cb_row1_col0, #T_540cb_row1_col1, #T_540cb_row1_col2, #T_540cb_row1_col3, #T_540cb_row1_col4, #T_540cb_row1_col5, #T_540cb_row1_col6, #T_540cb_row1_col7, #T_540cb_row1_col8, #T_540cb_row1_col9, #T_540cb_row2_col0, #T_540cb_row2_col1, #T_540cb_row2_col2, #T_540cb_row2_col3, #T_540cb_row2_col4, #T_540cb_row2_col5, #T_540cb_row2_col6, #T_540cb_row2_col7, #T_540cb_row2_col8, #T_540cb_row2_col9 {\n",
       "  background-color: white;\n",
       "  color: black;\n",
       "  border-color: black;\n",
       "  border-style: solid;\n",
       "  border-width: 1px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_540cb\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_540cb_level0_col0\" class=\"col_heading level0 col0\" >1st Most Common</th>\n",
       "      <th id=\"T_540cb_level0_col1\" class=\"col_heading level0 col1\" >2nd Most Common</th>\n",
       "      <th id=\"T_540cb_level0_col2\" class=\"col_heading level0 col2\" >3rd Most Common</th>\n",
       "      <th id=\"T_540cb_level0_col3\" class=\"col_heading level0 col3\" >4th Most Common</th>\n",
       "      <th id=\"T_540cb_level0_col4\" class=\"col_heading level0 col4\" >5th Most Common</th>\n",
       "      <th id=\"T_540cb_level0_col5\" class=\"col_heading level0 col5\" >6th Most Common</th>\n",
       "      <th id=\"T_540cb_level0_col6\" class=\"col_heading level0 col6\" >7th Most Common</th>\n",
       "      <th id=\"T_540cb_level0_col7\" class=\"col_heading level0 col7\" >8th Most Common</th>\n",
       "      <th id=\"T_540cb_level0_col8\" class=\"col_heading level0 col8\" >9th Most Common</th>\n",
       "      <th id=\"T_540cb_level0_col9\" class=\"col_heading level0 col9\" >10th Most Common</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Method</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_540cb_level0_row0\" class=\"row_heading level0 row0\" >Basic</th>\n",
       "      <td id=\"T_540cb_row0_col0\" class=\"data row0 col0\" >team</td>\n",
       "      <td id=\"T_540cb_row0_col1\" class=\"data row0 col1\" >data</td>\n",
       "      <td id=\"T_540cb_row0_col2\" class=\"data row0 col2\" >performance</td>\n",
       "      <td id=\"T_540cb_row0_col3\" class=\"data row0 col3\" >based</td>\n",
       "      <td id=\"T_540cb_row0_col4\" class=\"data row0 col4\" >football</td>\n",
       "      <td id=\"T_540cb_row0_col5\" class=\"data row0 col5\" >classification</td>\n",
       "      <td id=\"T_540cb_row0_col6\" class=\"data row0 col6\" >match</td>\n",
       "      <td id=\"T_540cb_row0_col7\" class=\"data row0 col7\" >neural</td>\n",
       "      <td id=\"T_540cb_row0_col8\" class=\"data row0 col8\" >using</td>\n",
       "      <td id=\"T_540cb_row0_col9\" class=\"data row0 col9\" >model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_540cb_level0_row1\" class=\"row_heading level0 row1\" >Stemming</th>\n",
       "      <td id=\"T_540cb_row1_col0\" class=\"data row1 col0\" >team</td>\n",
       "      <td id=\"T_540cb_row1_col1\" class=\"data row1 col1\" >perform</td>\n",
       "      <td id=\"T_540cb_row1_col2\" class=\"data row1 col2\" >use</td>\n",
       "      <td id=\"T_540cb_row1_col3\" class=\"data row1 col3\" >data</td>\n",
       "      <td id=\"T_540cb_row1_col4\" class=\"data row1 col4\" >model</td>\n",
       "      <td id=\"T_540cb_row1_col5\" class=\"data row1 col5\" >predict</td>\n",
       "      <td id=\"T_540cb_row1_col6\" class=\"data row1 col6\" >classifi</td>\n",
       "      <td id=\"T_540cb_row1_col7\" class=\"data row1 col7\" >footbal</td>\n",
       "      <td id=\"T_540cb_row1_col8\" class=\"data row1 col8\" >base</td>\n",
       "      <td id=\"T_540cb_row1_col9\" class=\"data row1 col9\" >network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_540cb_level0_row2\" class=\"row_heading level0 row2\" >Lemmatization</th>\n",
       "      <td id=\"T_540cb_row2_col0\" class=\"data row2 col0\" >team</td>\n",
       "      <td id=\"T_540cb_row2_col1\" class=\"data row2 col1\" >data</td>\n",
       "      <td id=\"T_540cb_row2_col2\" class=\"data row2 col2\" >performance</td>\n",
       "      <td id=\"T_540cb_row2_col3\" class=\"data row2 col3\" >model</td>\n",
       "      <td id=\"T_540cb_row2_col4\" class=\"data row2 col4\" >base</td>\n",
       "      <td id=\"T_540cb_row2_col5\" class=\"data row2 col5\" >network</td>\n",
       "      <td id=\"T_540cb_row2_col6\" class=\"data row2 col6\" >match</td>\n",
       "      <td id=\"T_540cb_row2_col7\" class=\"data row2 col7\" >football</td>\n",
       "      <td id=\"T_540cb_row2_col8\" class=\"data row2 col8\" >classification</td>\n",
       "      <td id=\"T_540cb_row2_col9\" class=\"data row2 col9\" >analysis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17a3d7750>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TA_results = results_df(words_basic_TA, words_stemming_TA, words_lemm_TA)\n",
    "\n",
    "TA_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Identifying the Most Common Bigrams and Trigrams in Title, Abstract and then Title and Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Most Common Bigrams and Trigrams in Title Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common bigrams in Title: [(('neural', 'network'), 11), (('artificial', 'neural'), 8), (('data', 'mining'), 7), (('neural', 'networks'), 6), (('team', 'handball'), 4), (('’s', 'basketball'), 3), (('olympic', 'games'), 3), (('football', 'using'), 3), (('team', 'performance'), 3), (('technical', 'tactical'), 3)]\n",
      "Most common trigrams in Title: [(('artificial', 'neural', 'network'), 5), (('artificial', 'neural', 'networks'), 3), (('rbf', 'neural', 'network'), 2), (('women', '’s', 'basketball'), 2), (('self', 'organising', 'maps'), 2), (('team', 'handball', 'means'), 2), (('handball', 'means', 'artificial'), 2), (('means', 'artificial', 'neural'), 2), (('explaining', 'match', 'outcome'), 2), (('team', 'performance', 'indicators'), 2)]\n"
     ]
    }
   ],
   "source": [
    "from nltk import bigrams, trigrams\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt',quiet = True)\n",
    "\n",
    "def bitri_preproc(text):\n",
    "    # Convert to lowercase, remove punctuation, and split into words\n",
    "    words = text.lower().translate(str.maketrans('-/', '  ')).split()\n",
    "    # Remove stopwords & return\n",
    "    return [word for word in words if word not in stop_words]\n",
    "\n",
    "# Combine and preprocess titles\n",
    "all_words = []\n",
    "for title in references['Title'].fillna(''):\n",
    "    all_words.extend(bitri_preproc(title))\n",
    "\n",
    "# Find the most common bigrams and trigrams\n",
    "bigram_counts = Counter(bigrams(all_words))\n",
    "trigram_counts = Counter(trigrams(all_words))\n",
    "\n",
    "title_bigrams = bigram_counts.most_common(10)\n",
    "title_trigrams = trigram_counts.most_common(10)\n",
    "\n",
    "print(\"Most common bigrams in Title:\", title_bigrams)\n",
    "print(\"Most common trigrams in Title:\", title_trigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Most Common Bigrams and Trigrams in Abstract Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common bigrams in abstracts in Abstract: [(('performance', 'indicators'), 12), (('team', 'performance'), 10), (('match', 'outcome'), 7), (('ground', 'reaction'), 7), (('machine', 'learning'), 6), (('ball', 'possession'), 5), (('logistic', 'regression'), 5), (('classification', 'accuracy'), 5), (('mir', '146a'), 5), (('146a', '5p'), 5)]\n",
      "Most common trigrams in abstracts in Abstract: [(('team', 'performance', 'indicators'), 8), (('mir', '146a', '5p'), 5), (('ground', 'reaction', 'force'), 4), (('class', 'errors', 'ranging'), 3), (('ci', 'classification', 'tree'), 3), (('provided', 'greatest', 'probability'), 3), (('\"field', 'goal', 'percentage\",'), 3), (('support', 'vector', 'machine'), 3), (('one', 'versus', 'one'), 3), (('time', 'course', 'ground'), 3)]\n"
     ]
    }
   ],
   "source": [
    "#Preprocess and combine all abstracts into one list\n",
    "all_words = []\n",
    "for abstract in ref_abs['Abstract'].fillna(''):\n",
    "    all_words.extend(bitri_preproc(abstract))\n",
    "\n",
    "#Generate and count bigrams and trigrams\n",
    "bigram_counts = Counter(bigrams(all_words))\n",
    "trigram_counts = Counter(trigrams(all_words))\n",
    "\n",
    "#Get the 10 most common bigrams and trigrams\n",
    "abs_bigrams = bigram_counts.most_common(10)\n",
    "abs_trigrams = trigram_counts.most_common(10)\n",
    "\n",
    "#Display the results\n",
    "print(\"Most common bigrams in abstracts in Abstract:\", abs_bigrams)\n",
    "print(\"Most common trigrams in abstracts in Abstract:\", abs_trigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Most Common Bigrams and Trigrams in Abstract and Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common bigrams in Title and Abstract: [(('performance', 'indicators'), 14), (('team', 'performance'), 13), (('neural', 'network'), 12), (('match', 'outcome'), 9), (('machine', 'learning'), 8), (('data', 'mining'), 8), (('artificial', 'neural'), 8), (('olympic', 'games'), 7), (('neural', 'networks'), 7), (('ground', 'reaction'), 7)]\n",
      "Most common trigrams in Title and Abstract: [(('team', 'performance', 'indicators'), 10), (('artificial', 'neural', 'network'), 5), (('support', 'vector', 'machine'), 5), (('mir', '146a', '5p'), 5), (('one', 'versus', 'one'), 4), (('ground', 'reaction', 'force'), 4), (('artificial', 'neural', 'networks'), 3), (('class', 'errors', 'ranging'), 3), (('ci', 'classification', 'tree'), 3), (('provided', 'greatest', 'probability'), 3)]\n"
     ]
    }
   ],
   "source": [
    "#Preprocess and combine all texts into one list\n",
    "all_words = []\n",
    "for text in combined_texts:\n",
    "    all_words.extend(bitri_preproc(text))\n",
    "\n",
    "#Generate and count bigrams and trigrams\n",
    "bigram_counts = Counter(bigrams(all_words))\n",
    "trigram_counts = Counter(trigrams(all_words))\n",
    "\n",
    "#Get the 10 most common bigrams and trigrams\n",
    "TA_bigrams = bigram_counts.most_common(10)\n",
    "TA_trigrams = trigram_counts.most_common(10)\n",
    "\n",
    "# Display the results\n",
    "print(\"Most common bigrams in Title and Abstract:\", TA_bigrams)\n",
    "print(\"Most common trigrams in Title and Abstract:\", TA_trigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Export information of interest to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>String</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>team</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>performance</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>base</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>team performance indicators</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>artificial neural network</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>support vector machine</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>one versus one</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>ground reaction force</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         String  Frequency\n",
       "0                          team         49\n",
       "1                          data         37\n",
       "2                   performance         34\n",
       "3                         model         30\n",
       "4                          base         26\n",
       "..                          ...        ...\n",
       "77  team performance indicators         10\n",
       "78    artificial neural network          5\n",
       "79       support vector machine          5\n",
       "81               one versus one          4\n",
       "82        ground reaction force          4\n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.most_common(35), bigram_counts.most_common(20), trigram_counts.most_common(10)\n",
    "\n",
    "#Subsetting the lemmatized word counts to only include frequencies geq 11\n",
    "subset_word_counts = [item for item in word_counts.most_common() if item[1] >= 11]\n",
    "#Subsetting the bigram counts to only include frequencies geq 4\n",
    "subset_bigram_counts = [item for item in bigram_counts.most_common() if item[1] >= 4]\n",
    "#Subsetting the trigram counts to only include frequencies geq 4\n",
    "subset_trigram_counts = [item for item in trigram_counts.most_common() if item[1] >= 4]\n",
    "\n",
    "counts = subset_word_counts + subset_bigram_counts + subset_trigram_counts\n",
    "\n",
    "counts_df = pd.DataFrame(counts, columns=[\"String\", \"Frequency\"])\n",
    "#Concatenate bigrams/trigrams\n",
    "counts_df['String'] = counts_df['String'].apply(lambda x: ' '.join(x) if isinstance(x, tuple) else x)\n",
    "#Remove some of the entries that have numerical characters in them stemming from results and references to other papers\n",
    "counts_df = counts_df[counts_df['String'].apply(lambda x: not any(char.isdigit() for char in x))]\n",
    "\n",
    "#Export to csv for future use\n",
    "counts_df.to_csv(os.path.join('..','results','common_strings.csv'), index=False)\n",
    "\n",
    "#Display a preview of the dataframe\n",
    "counts_df "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
