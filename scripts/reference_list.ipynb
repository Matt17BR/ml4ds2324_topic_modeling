{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Russell S, Norvig P</td>\n",
       "      <td>Artificial Intelligence: a modern approach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Witten IH, Frank E, Hall MA, et al</td>\n",
       "      <td>Data Mining: practical Machine Learning tools ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zaki MJ, Meira Jr, W</td>\n",
       "      <td>Data Mining and analysis: fundamental concepts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Passfield L, Hopker JG</td>\n",
       "      <td>A mine of information: can sports analytics pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rein R, Memmert D</td>\n",
       "      <td>Big data and tactical analysis in elite soccer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Dalton-Barron NE, McLaren SJ, Black CJ, et al</td>\n",
       "      <td>Identifying contextual influences on training ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>McLaren SJ, Weston M, Smith A, et al</td>\n",
       "      <td>Variability of physical performance and player...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Oliveira WK, Jesus K, Andrade AD, et al</td>\n",
       "      <td>Monitoring training load in beach volleyball p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Düking P, Achtzehn S, Holmberg HC, Sperlich B</td>\n",
       "      <td>Integrated framework of load monitoring by a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Austen K</td>\n",
       "      <td>What could derail the wearables revolution? Na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Author  \\\n",
       "0                              Russell S, Norvig P   \n",
       "1               Witten IH, Frank E, Hall MA, et al   \n",
       "2                             Zaki MJ, Meira Jr, W   \n",
       "3                           Passfield L, Hopker JG   \n",
       "4                                Rein R, Memmert D   \n",
       "..                                             ...   \n",
       "98   Dalton-Barron NE, McLaren SJ, Black CJ, et al   \n",
       "99            McLaren SJ, Weston M, Smith A, et al   \n",
       "100        Oliveira WK, Jesus K, Andrade AD, et al   \n",
       "101  Düking P, Achtzehn S, Holmberg HC, Sperlich B   \n",
       "102                                       Austen K   \n",
       "\n",
       "                                                 Title  \n",
       "0           Artificial Intelligence: a modern approach  \n",
       "1    Data Mining: practical Machine Learning tools ...  \n",
       "2    Data Mining and analysis: fundamental concepts...  \n",
       "3    A mine of information: can sports analytics pr...  \n",
       "4    Big data and tactical analysis in elite soccer...  \n",
       "..                                                 ...  \n",
       "98   Identifying contextual influences on training ...  \n",
       "99   Variability of physical performance and player...  \n",
       "100  Monitoring training load in beach volleyball p...  \n",
       "101  Integrated framework of load monitoring by a c...  \n",
       "102  What could derail the wearables revolution? Na...  \n",
       "\n",
       "[103 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from pypdf import PdfReader\n",
    "\n",
    "# Function to extract references from a PDF file using a context-aware pattern\n",
    "def parse_references(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    refs = []\n",
    "    ref_section = False # Use as a flag to find the references section\n",
    "    last_ref_num = 0 # To track the last reference number\n",
    "\n",
    "    for page in reader.pages:\n",
    "        # Extract text on a page by page basis\n",
    "        text = page.extract_text()\n",
    "        # When the \"References\" bit is found, cut out the text preceding it\n",
    "        if \"References\" in text:\n",
    "            ref_section = True\n",
    "            text = text.split(\"References\", 1)[1]\n",
    "        if ref_section:\n",
    "            # Find all matches of reference pattern\n",
    "            for match in re.finditer(r'(\\d+)\\. (.*?\\..*?)\\.', text, re.DOTALL):\n",
    "                current_ref_num = int(match.group(1))\n",
    "                # Append reference if the current reference number is sequential\n",
    "                if current_ref_num == last_ref_num + 1:\n",
    "                    refs.append(match.group(2))\n",
    "                    last_ref_num = current_ref_num\n",
    "    # Use dot as column separator for Author and Title (as in the PDF)\n",
    "    references = pd.DataFrame(refs)[0].str.split('.', n=1, expand=True)\n",
    "    references.columns = ['Author', 'Title']\n",
    "    # Replace newline characters with space and strip leading whitespace\n",
    "    return references.applymap(lambda x: x.replace('\\n', ' ').strip())\n",
    "\n",
    "pdf = os.path.join('..','paper','s40798-019-0202-3.pdf')\n",
    "\n",
    "# Extract references using the context-aware pattern from the uploaded PDF file\n",
    "references = parse_references(pdf)\n",
    "\n",
    "references.to_csv(os.path.join('..','results','paper_refs.csv'), index=False)\n",
    "\n",
    "references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(or artificially defined environments such as the simulated chessboard) and into the real world,  there is  In Human Compatible (Russell 2019), I suggest three principles underlying a new\n",
      "With its comprehensive coverage, algorithmic perspective, and wealth of examples, this  book offers solid guidance in data mining for students, researchers, and practitioners alike.\n",
      "of the science of sport alongside extensive skills for data handling and analysis. Next we  provide 2 examples of the kind of  that illustrate different ways of mining and modeling data to\n",
      "amount of available data is becoming  big data technologies from industrial data analytics  domains address these problems. Further, the present work provide an overview how big data\n",
      "ask why scientists should care about data science. To answer, we discuss data science from  three  Although each of the three is a critical component of data science, we argue that the\n",
      "Machine learning (ML) is one of the intelligent methodologies that have shown promising   In doing so, we identify the learning methodologies utilised, data sources, appropriate means\n",
      "than humans can are exciting advances for clinicians. But, the recurring trope of pitting humans   The desirable attributes of humans who choose the path of caring for others include, in\n",
      "Clinicians and researchers have long envisioned the day when computers could assist with difficult decisions in complex clinical situations. The first article on this subject appeared in the scientific literature about 60 years ago, 1 and the notion of computer-based clinical decision support has subsequently been a dominant topic for informatics research. Two recent Viewpoints in JAMA highlighted the promise of deep learning in medicine. 2, 3 Such new data analytic methods have much to offer in interpreting large and complex data sets\n",
      "more accurate than 10%, even though the models anticipate growing trends in these series.   M2 measures the money supply more broadly than M1, which only takes into account cash\n",
      "number of scientific publications related to injury prevention and performance enhancement  in football in the last 10–15 years. Despite that our impact as sports science and medicine\n",
      "[60] A study by Borresen and Lambert[61] found correlations of r = 0.76 between TRIMP and  session RPE and r = 0.84 between summated heart rate zone method and the session RPE\n",
      "Studies were combined using a Poisson random effects regression model.  However, before  implementing any injury prevention measure, it is essential to know the injury profile of youth\n",
      "reporting in completed reviews. We describe the development of a reporting guideline, the  Preferred Reporting Items  PRISMA-P consists of a 17-item checklist intended to facilitate the\n",
      "of athlete  monitor changes in athlete well-being in response to training. Subjective measures  may stand alone, or be incorporated into a mixed methods approach to athlete monitoring,\n",
      "such as node classification, link prediction, and clustering. Graph neural networks (GNNs)  are  In the following paragraphs, we will illustrate the fundamental motivations of graph neural\n",
      "In this paper, we review and examine important shape representation and  affine models  are generated from the model shape. Since the space of affine transformations from the model\n",
      "The lower layer is the sidechain of participating entities (construction project teams),  containing private transaction records and copies of the main blockchain. The upper layer is the\n",
      "be used to predict PPIs with an accuracy and coverage that are superior to predictions based  on non- Experimental tests of a number of predictions demonstrate the ability of the PrePPI\n",
      "that ANNs can be used to identify offensive tactical patterns, to analyze the interaction  between offensive and defensive teams, to evaluate tactical training during a game and to predict\n",
      "TA Hassan is a full-time employee of Pfizer Inc.  This article summarizes the resulting  discussion of the expert meeting and focuses on ED evaluation. The management of ED is\n",
      "In addition, we examined the impact of study quality on estimation of predictive accuracy  according to individual quality items and according to an overall quality level incorporating\n",
      "already help to understand teams’ tactics. Ultimately, a main goal of tactical analysis is to gain   One approach analysing tactical interaction between groups like offence and defence was\n",
      "This study aims to predict the potential pattern of  the current study and intelligent  prediction of artificial neural network ( Nevertheless, the prediction method techniques for the\n",
      "The methodology of the machine learning based AC algorithm (L a ), our machine learning  based AC algorithm is a spectral  The keys to the success of the machine learning based AC\n",
      "In this study, team rankings were predicted using the machine learning method. The ANN   used in the present study to predict team rankings in the professional male volleyball league.\n",
      "measurements of SOC content and fluxes at field, landscape and regional scales. This paper  provides a critical review of optical RS techniques for such applications. The first part of the\n",
      "The aim of this study is to rank some features that characterize the psychological dynamics of cooperative team work in order to determine priorities for interventions and formation: leading positive feedback, cooperative manager and collaborative manager features. From a dataset of 20 cooperative sport teams (403 soccer players), the characteristics of the prototypical sports teams are studied using an average Bayesian network (BN) and two special types of BNs, the Bayesian classifiers: naive Bayes (NB) and tree augmented naive\n",
      "This paper describes models for detecting individual and team ball possession in soccer based on position data. The types of ball possession are classified as Individual Ball Possession (IBC), Individual Ball Action (IBA), Individual Ball Control (IBC), Team Ball Possession (TBP), Team Ball Control (TBC) und Team Playmaking (TPM) according to different starting points and endpoints and the type of ball control involved. The machine learning approach used is able to determine how long the ball spends in the sphere of\n",
      "Healey and Enns showed that color distance, linear separation, and color category must all   to select discrete collections of equally distinguishable colors [Healey 96, Healey & Enns 99].\n",
      "This work investigates the effectiveness of using computer-based machine learning regression algorithms and meta-regression methods to predict performance data for Australian football players based on parameters collected during daily physiological tests. Three experiments are described. The first uses all available data with a variety of regression techniques. The second uses a subset of features selected from the available data using the Random Forest method. The third used meta-regression with the selected\n",
      "opposition for a given match) to explain match outcome (Win/ as the most influential in  explaining match outcome, with two  slightly reduced ability to explain match outcome (81.0% and\n",
      "to their non-drafted counterparts (Woods et al., Citation2016a). However, this study did not  delineate the use of technical skill indicators to classify players of differing field positions. This\n"
     ]
    },
    {
     "ename": "MaxTriesExceededException",
     "evalue": "Cannot Fetch from Google Scholar.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMaxTriesExceededException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Splitting the title field and taking the first five words\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit()[:\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m---> 25\u001b[0m     abstracts\u001b[38;5;241m.\u001b[39mappend(\u001b[43mget_abstract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauthor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(abstracts)\n",
      "Cell \u001b[0;32mIn[52], line 5\u001b[0m, in \u001b[0;36mget_abstract\u001b[0;34m(author, title)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_abstract\u001b[39m(author, title):\n\u001b[0;32m----> 5\u001b[0m     search_query \u001b[38;5;241m=\u001b[39m \u001b[43mscholarly\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_pubs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mauthor\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtitle\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m         paper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(search_query)\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/scholarly/_scholarly.py:156\u001b[0m, in \u001b[0;36m_Scholarly.search_pubs\u001b[0;34m(self, query, patents, citations, year_low, year_high, sort_by, include_last_year, start_index)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Searches by query and returns a generator of Publication objects\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m:param query: terms to be searched\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m \n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    153\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_url(_PUBSEARCH\u001b[38;5;241m.\u001b[39mformat(requests\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mquote(query)), patents\u001b[38;5;241m=\u001b[39mpatents,\n\u001b[1;32m    154\u001b[0m                           citations\u001b[38;5;241m=\u001b[39mcitations, year_low\u001b[38;5;241m=\u001b[39myear_low, year_high\u001b[38;5;241m=\u001b[39myear_high,\n\u001b[1;32m    155\u001b[0m                           sort_by\u001b[38;5;241m=\u001b[39msort_by, include_last_year\u001b[38;5;241m=\u001b[39minclude_last_year, start_index\u001b[38;5;241m=\u001b[39mstart_index)\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__nav\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_publications\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/scholarly/_navigator.py:283\u001b[0m, in \u001b[0;36mNavigator.search_publications\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch_publications\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _SearchScholarIterator:\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a Publication Generator given a url\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03m    :param url: the url where publications can be found.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m    :rtype: {_SearchScholarIterator}\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_SearchScholarIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/scholarly/publication_parser.py:53\u001b[0m, in \u001b[0;36m_SearchScholarIterator.__init__\u001b[0;34m(self, nav, url)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pubtype \u001b[38;5;241m=\u001b[39m PublicationSource\u001b[38;5;241m.\u001b[39mPUBLICATION_SEARCH_SNIPPET \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/scholar?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m url \u001b[38;5;28;01melse\u001b[39;00m PublicationSource\u001b[38;5;241m.\u001b[39mJOURNAL_CITATION_LIST\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nav \u001b[38;5;241m=\u001b[39m nav\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_total_results()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_parser \u001b[38;5;241m=\u001b[39m PublicationParser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nav)\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/scholarly/publication_parser.py:59\u001b[0m, in \u001b[0;36m_SearchScholarIterator._load_url\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_url\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# this is temporary until setup json file\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nav\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_soup\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgs_r gs_or gs_scl\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgsc_mpat_ttl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/scholarly/_navigator.py:226\u001b[0m, in \u001b[0;36mNavigator._get_soup\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_soup\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BeautifulSoup:\n\u001b[1;32m    225\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the BeautifulSoup for a page on scholar.google.com\"\"\"\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m     html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://scholar.google.com\u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m     html \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    228\u001b[0m     res \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/scholarly/_navigator.py:177\u001b[0m, in \u001b[0;36mNavigator._get_page\u001b[0;34m(self, pagerequest, premium)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_page(pagerequest, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxTriesExceededException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot Fetch from Google Scholar.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mMaxTriesExceededException\u001b[0m: Cannot Fetch from Google Scholar."
     ]
    }
   ],
   "source": [
    "from scholarly import scholarly\n",
    "\n",
    "# Function to search for a paper and get its abstract\n",
    "def get_abstract(author, title):\n",
    "    search_query = scholarly.search_pubs(f'{author} {title}')\n",
    "    try:\n",
    "        paper = next(search_query)\n",
    "        print(paper['bib']['abstract'])\n",
    "        return paper['bib']['abstract'] if 'abstract' in paper['bib'] else \"Abstract not available\"\n",
    "    except StopIteration:\n",
    "        return \"No results found\"\n",
    "    except KeyError:\n",
    "        return \"Abstract not available\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "# Retrieve abstracts for the specified papers\n",
    "abstracts = []\n",
    "for index, row in references.iterrows():\n",
    "    # Splitting the author field and taking the first part before the comma\n",
    "    author = row['Author'].split(',')[0].strip()\n",
    "\n",
    "    # Splitting the title field and taking the first five words\n",
    "    title = ' '.join(row['Title'].split()[:3])\n",
    "    abstracts.append(get_abstract(author, title))\n",
    "print(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stuart Russell Abstract A long tradition in philosophy and economics equates intelligence   that can be expected to achieve one’s objectives. This framework is so pervasive within AI that\n"
     ]
    }
   ],
   "source": [
    "from scholarly import scholarly\n",
    "\n",
    "def search_abstract(author, title):\n",
    "    search_query = scholarly.search_pubs(f\"{title} {author}\")\n",
    "    try:\n",
    "        paper = next(search_query)\n",
    "        return paper['bib']['abstract']\n",
    "    except StopIteration:\n",
    "        return \"No results found\"\n",
    "    except KeyError:\n",
    "        return \"Abstract not available\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "# Example usage\n",
    "abstract = search_abstract(\"Russell S\", \"Artificial Intelligence\")\n",
    "print(abstract)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['26185241'], [], [], ['27967295'], ['27610328'], ['28784795'], [], [], ['30398550'], ['25859590'], [], ['27252168'], [], ['19691366'], ['29283933'], ['24149722'], ['33782057'], ['26423706'], ['21833989'], [], [], [], [], ['24993662'], [], [], [], [], [], [], [], [], [], [], [], ['28692649'], [], [], ['26176890'], ['28125339'], [], ['29910456'], [], ['25816795'], [], ['29910361'], ['23409787'], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], ['29276071'], [], ['27194668'], [], ['29629182'], ['29266094'], ['30044858'], ['27918659'], ['29283691'], ['25721800'], ['29321637'], ['27159303'], ['7563290'], ['9555629'], [], ['23486837'], [], [], ['27166289'], ['25977310'], ['27486488'], ['27101130'], ['27482527'], ['27095747'], ['30253926'], ['24149123'], ['25435773'], ['28530474'], ['25623172'], ['28601588'], ['26519521'], ['24585673'], ['29226164'], ['24918302'], ['29979279'], ['26118848'], [], ['29783763'], ['26333453']]\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "\n",
    "def search_pubmed(query, email):\n",
    "    Entrez.email = email\n",
    "    handle = Entrez.esearch(db='pubmed',sort='relevance',\n",
    "    retmax='5',\n",
    "    retmode='xml',\n",
    "    term=query)\n",
    "    results = Entrez.read(handle)\n",
    "    return results\n",
    "\n",
    "def fetch_details(id_list, email):\n",
    "    ids = ','.join(id_list)\n",
    "    Entrez.email = email\n",
    "    handle = Entrez.efetch(db='pubmed',\n",
    "    retmode='xml',\n",
    "    id=ids)\n",
    "    results = Entrez.read(handle)\n",
    "    return results\n",
    "\n",
    "mazza = 'matteo.mazzarelli@gmail.com'\n",
    "\n",
    "studyids = []\n",
    "for index, row in references.iterrows():\n",
    "    # Splitting the author field and taking the first part before the comma\n",
    "    author = row['Author'].split(',')[0].strip()\n",
    "\n",
    "    # Splitting the title field and taking the first five words\n",
    "    title = ' '.join(row['Title'].split()[:8])\n",
    "\n",
    "    # Forming the query and searching\n",
    "    studies = search_pubmed(f\"{author} {title}\", mazza)\n",
    "    studyids.append(studies['IdList'][:1])\n",
    "print(studyids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, list found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m pubdate_year_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m pubdate_month_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 8\u001b[0m papers \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_details\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudyids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmazza\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, paper \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(papers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPubmedArticle\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m     11\u001b[0m     title_list\u001b[38;5;241m.\u001b[39mappend(paper[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedlineCitation\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArticle\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArticleTitle\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[41], line 13\u001b[0m, in \u001b[0;36mfetch_details\u001b[0;34m(id_list, email)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_details\u001b[39m(id_list, email):\n\u001b[0;32m---> 13\u001b[0m     ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mid_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     Entrez\u001b[38;5;241m.\u001b[39memail \u001b[38;5;241m=\u001b[39m email\n\u001b[1;32m     15\u001b[0m     handle \u001b[38;5;241m=\u001b[39m Entrez\u001b[38;5;241m.\u001b[39mefetch(db\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpubmed\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     16\u001b[0m     retmode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxml\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mids)\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, list found"
     ]
    }
   ],
   "source": [
    "title_list = []\n",
    "abstract_list = []\n",
    "journal_list = []\n",
    "language_list = []\n",
    "pubdate_year_list = []\n",
    "pubdate_month_list = []\n",
    "\n",
    "papers = fetch_details(studyids, mazza)\n",
    "    \n",
    "for i, paper in enumerate(papers['PubmedArticle']):\n",
    "    title_list.append(paper['MedlineCitation']['Article']['ArticleTitle'])\n",
    "\n",
    "    try:\n",
    "        abstract_list.append(paper['MedlineCitation']['Article']['Abstract']['AbstractText'][0])\n",
    "    except:\n",
    "        abstract_list.append('No Abstract')\n",
    "\n",
    "    journal_list.append(paper['MedlineCitation']['Article']['Journal']['Title'])\n",
    "    language_list.append(paper['MedlineCitation']['Article']['Language'][0])\n",
    "\n",
    "    try:\n",
    "        pubdate_year_list.append(paper['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']['Year'])\n",
    "    except:\n",
    "        pubdate_year_list.append('No Data')\n",
    "\n",
    "    try:\n",
    "        pubdate_month_list.append(paper['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']['Month'])\n",
    "    except:\n",
    "        pubdate_month_list.append('No Data')\n",
    "\n",
    "df = pd.DataFrame(list(zip(\n",
    "    title_list, abstract_list, journal_list, language_list, pubdate_year_list, pubdate_month_list\n",
    ")),\n",
    "columns=[\n",
    "    'Title', 'Abstract', 'Journal', 'Language', 'Year', 'Month'\n",
    "])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
